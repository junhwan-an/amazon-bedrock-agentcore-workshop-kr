{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndexì™€ AgentCore Memory - í•™ìˆ  ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ (ì¥ê¸° ë©”ëª¨ë¦¬)\n",
    "\n",
    "## ì†Œê°œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Amazon Bedrock AgentCore Memory ê¸°ëŠ¥ì„ LlamaIndexì™€ í†µí•©í•˜ì—¬ **ì¥ê¸° ë©”ëª¨ë¦¬** ì§€ì†ì„±ì„ ê°–ì¶˜ í•™ìˆ  ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—¬ëŸ¬ ì—°êµ¬ ì„¸ì…˜ì— ê±¸ì³ ë©”ëª¨ë¦¬ê°€ ìœ ì§€ë˜ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ìˆ˜ì£¼ ë° ìˆ˜ê°œì›”ì˜ ì—°êµ¬ ì‘ì—… ë™ì•ˆ ëˆ„ì  ì§€ì‹ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## ì•„í‚¤í…ì²˜ ê°œìš”\n",
    "\n",
    "![LlamaIndex AgentCore Long-Term Memory Architecture](LlamaIndex-AgentCore-LTM-Arch.png)\n",
    "\n",
    "## íŠœí† ë¦¬ì–¼ ì„¸ë¶€ì‚¬í•­\n",
    "\n",
    "**íŠœí† ë¦¬ì–¼ ì„¸ë¶€ì‚¬í•­:**\n",
    "- **íŠœí† ë¦¬ì–¼ ìœ í˜•**: ì¥ê¸° ì„¸ì…˜ ê°„ ë©”ëª¨ë¦¬\n",
    "- **Agent ì‚¬ìš© ì‚¬ë¡€**: í•™ìˆ  ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸\n",
    "- **Agentic Framework**: LlamaIndex\n",
    "- **LLM model**: Anthropic Claude 3.7 Sonnet\n",
    "- **íŠœí† ë¦¬ì–¼ êµ¬ì„±ìš”ì†Œ**: AgentCore ì¥ê¸° ë©”ëª¨ë¦¬, LlamaIndex Agent, ì—°êµ¬ ë„êµ¬\n",
    "- **ì˜ˆì œ ë³µì¡ë„**: ê³ ê¸‰\n",
    "\n",
    "## ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜\n",
    "\n",
    "**ê¸°ì—… ì—°êµ¬ ì¸í…”ë¦¬ì „ìŠ¤**: ê¸°ê´€ ì§€ì‹ì„ ì¶•ì í•˜ê³ , ì—°êµ¬ ì§„í™”ë¥¼ ì¶”ì í•˜ë©°, í”„ë¡œì íŠ¸ì™€ ê¸°ê°„ì— ê±¸ì³ í¬ê´„ì ì¸ í•™ìˆ  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ” ì§€ì†ì ì¸ AI ë©”ëª¨ë¦¬ë¡œ ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ í˜ì‹ í•˜ì„¸ìš”.\n",
    "\n",
    "**ì£¼ìš” ì „ë¬¸ì  ì´ì :**\n",
    "- **ì—°êµ¬ ì—°ì†ì„±**: ì—°êµ¬ ë‹¨ê³„ì™€ íŒ€ êµ¬ì„±ì› ê°„ì˜ ì›í™œí•œ ì§€ì‹ ì „ë‹¬\n",
    "- **ê¸°ê´€ ë©”ëª¨ë¦¬**: ì¤‘ìš”í•œ ì—°êµ¬ í†µì°°ë ¥, ë°©ë²•ë¡  ë° ê²°ê³¼ë¥¼ ì˜êµ¬ì ìœ¼ë¡œ ë³´ì¡´\n",
    "- **í”„ë¡œì íŠ¸ ê°„ ì¸í…”ë¦¬ì „ìŠ¤**: ì—¬ëŸ¬ ì—°êµ¬ ì´ë‹ˆì…”í‹°ë¸Œì— ê±¸ì¹œ íŒ¨í„´ê³¼ ì—°ê²° ì‹ë³„\n",
    "- **ì—°êµ¬ë¹„ ì œì•ˆ ìš°ìˆ˜ì„±**: ì„¤ë“ë ¥ ìˆëŠ” ìê¸ˆ ì‹ ì²­ì„ ìœ„í•œ ê³¼ê±° ì—°êµ¬ ë°ì´í„° í™œìš©\n",
    "- **í•™ìˆ  í˜‘ì—…**: ë‹¤ë…„ê°„ì˜ í˜‘ë ¥ ì—°êµ¬ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ìƒì„¸í•œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "- **ì¶œíŒ ì „ëµ**: ì „ëµì  ì¶œíŒ ê³„íšì„ ìœ„í•œ ì—°êµ¬ ì£¼ì œ ë° ì¸ìš© ë„¤íŠ¸ì›Œí¬ ì¶”ì \n",
    "\n",
    "## ì¥ê¸° ë©”ëª¨ë¦¬ êµ¬ì„±\n",
    "\n",
    "**ê¸°ìˆ  ì„¤ì •**: ì´ íŠœí† ë¦¬ì–¼ì€ 12ê°œì›” ë³´ì¡´ì„ ìœ„í•œ Semantic Strategyì™€ í•¨ê»˜ AgentCore Memoryë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "- **ë©”ëª¨ë¦¬ ìœ í˜•**: ìë™ í†µì°°ë ¥ ì¶”ì¶œì„ ê°–ì¶˜ Semantic strategy\n",
    "- **ë³´ì¡´ ê¸°ê°„**: ì—°êµ¬ ì—°ì†ì„±ì„ ìœ„í•œ 365ì¼ ì´ë²¤íŠ¸ ë§Œë£Œ\n",
    "- **ì„¸ì…˜ ê°„**: ë™ì¼í•œ actor_id + memory_id, ì—°êµ¬ ê¸°ê°„ë³„ë¡œ ë‹¤ë¥¸ session_id\n",
    "- **ê²€ìƒ‰ ê¸°ëŠ¥**: ì—°êµ¬ ê¸°ë¡ ì „ë°˜ì— ê±¸ì¹œ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì„ ìœ„í•œ ë‚´ì¥ ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬\n",
    "\n",
    "## ê¸°ìˆ  ê°œìš”\n",
    "\n",
    "**ì£¼ìš” ì¥ê¸° ë©”ëª¨ë¦¬ êµ¬ì„±ìš”ì†Œ:**\n",
    "1. **Semantic Strategy êµ¬ì„±**: 365ì¼ ë³´ì¡´ê³¼ í•¨ê»˜ ìë™ í†µì°°ë ¥ ì¶”ì¶œì„ ìœ„í•œ SemanticStrategy ì‚¬ìš©\n",
    "2. **ì„¸ì…˜ ê°„ ì§€ì†ì„±**: ë™ì¼í•œ actor_id + memory_id, ê¸°ê°„ë³„ë¡œ ë‹¤ë¥¸ session_idë¡œ ì§€ì‹ ì—°ì†ì„± í™œì„±í™”\n",
    "3. **ì»¤ìŠ¤í…€ ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬**: AgentCoreì˜ ë„¤ì´í‹°ë¸Œ search_long_term_memories()ë¥¼ LlamaIndex FunctionToolë¡œ ë˜í•‘\n",
    "4. **ì˜ë¯¸ë¡ ì  ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**: ëŒ€í™” ì´ë²¤íŠ¸ â†’ ì˜ë¯¸ë¡ ì  ë©”ëª¨ë¦¬ ë³€í™˜ì„ ìœ„í•œ 90ì´ˆ ëŒ€ê¸°\n",
    "5. **ë™ì  ì„¸ì…˜ ê´€ë¦¬**: ìœ ì—°í•œ ì„¸ì…˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ memory.context.session_id ì‚¬ìš©\n",
    "\n",
    "**í•™ìŠµ ë‚´ìš©:**\n",
    "\n",
    "- ì—¬ëŸ¬ ì—°êµ¬ ì„¸ì…˜ì— ê±¸ì³ ì§€ì†ì ì¸ AgentCore Memory ìƒì„±\n",
    "- ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ëˆ„ì  ì—°êµ¬ ì§€ì‹ êµ¬ì¶•\n",
    "- ì—°êµ¬ ê¸°ë¡ ì „ë°˜ì— ê±¸ì¹œ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ êµ¬í˜„\n",
    "- ì—°êµ¬ ì§„í™” ë° ì „ë¬¸ì„± ê°œë°œ ì¶”ì \n",
    "- ì„¸ì…˜ ê°„ ë©”ëª¨ë¦¬ ì§€ì†ì„± ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "## ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "- Python 3.10+\n",
    "- ì ì ˆí•œ ê¶Œí•œì´ ìˆëŠ” AWS ê³„ì •\n",
    "- AgentCore Memory ê¶Œí•œì´ ìˆëŠ” AWS IAM ì—­í• :\n",
    "  - `bedrock-agentcore:CreateMemory`\n",
    "  - `bedrock-agentcore:CreateEvent`\n",
    "  - `bedrock-agentcore:ListEvents`\n",
    "  - `bedrock-agentcore:RetrieveMemories`\n",
    "- Amazon Bedrock modelsì— ëŒ€í•œ ì•¡ì„¸ìŠ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 1: ì¢…ì†ì„± ì„¤ì¹˜ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries including semantic strategy toolkit\n",
    "%pip install llama-index-memory-bedrock-agentcore llama-index-llms-bedrock-converse boto3 bedrock-agentcore-starter-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager\n",
    "from bedrock_agentcore.memory.session import MemorySessionManager\n",
    "from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies.semantic import SemanticStrategy\n",
    "from llama_index.memory.bedrock_agentcore import AgentCoreMemory, AgentCoreMemoryContext\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 2: AgentCore Memory êµ¬ì„±\n",
    "\n",
    "ì¥ê¸° ì—°êµ¬ ì§€ì‹ì„ ìœ„í•œ AgentCore Memory ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ê°€ì ¸ì˜µë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AgentCore Memory with Semantic Strategy for long-term persistence\n",
    "region = os.getenv('AWS_REGION', 'us-east-1')\n",
    "memory_manager = MemoryManager(region_name=region)\n",
    "\n",
    "try:\n",
    "    # SemanticStrategy: ëŒ€í™”ì—ì„œ ìë™ìœ¼ë¡œ í†µì°°ë ¥ì„ ì¶”ì¶œí•˜ì—¬ ì¥ê¸° ë©”ëª¨ë¦¬ë¡œ ì €ì¥\n",
    "    memory = memory_manager.get_or_create_memory(\n",
    "        name=f'AcademicResearchSemantic_{int(datetime.now().timestamp())}',\n",
    "        strategies=[SemanticStrategy(name=\"researchLongTermMemory\")],\n",
    "        event_expiry_days=365  # 365ì¼ ë™ì•ˆ ì´ë²¤íŠ¸ ë³´ì¡´\n",
    "    )\n",
    "    memory_id = memory.get('id')\n",
    "    print(f\"âœ… Created Semantic Memory: {memory_id}\")\n",
    "    print(f\"   Status: {memory.get('status')}\")\n",
    "    print(f\"   Strategies: {[s.get('name') if isinstance(s, dict) else str(s) for s in memory.get('strategies', [])]}\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ê°€ ACTIVE ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸° (ì‚¬ìš© ê°€ëŠ¥ ìƒíƒœ)\n",
    "    if memory.get('status') != 'ACTIVE':\n",
    "        print(f\"\\nâ³ Waiting for memory to become ACTIVE (currently {memory.get('status')})...\")\n",
    "        import time\n",
    "        max_wait = 300  # ìµœëŒ€ 5ë¶„ ëŒ€ê¸°\n",
    "        waited = 0\n",
    "        while waited < max_wait:\n",
    "            time.sleep(10)\n",
    "            waited += 10\n",
    "            current_memory = memory_manager.get_memory(memory_id)\n",
    "            status = current_memory.get('status')\n",
    "            print(f\"   [{waited}s] Status: {status}\")\n",
    "            if status == 'ACTIVE':\n",
    "                print(f\"âœ… Memory is now ACTIVE! (took {waited} seconds)\")\n",
    "                break\n",
    "        else:  # while ë£¨í”„ê°€ break ì—†ì´ ì¢…ë£Œëœ ê²½ìš°\n",
    "            print(f\"âš ï¸  Memory still not ACTIVE after {max_wait}s. Proceeding anyway...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating memory: {e}\")\n",
    "    memory_id = \"your-memory-id-here\"  # ê¸°ì¡´ memory IDë¡œ êµì²´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 3: ì—°êµ¬ ë„êµ¬ êµ¬í˜„\n",
    "\n",
    "í•™ìˆ  ì—°êµ¬ ì‘ì—…ì„ ìœ„í•œ ì „ë¬¸ ë„êµ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paper_summary(title: str, authors: str, key_findings: str) -> str:\n",
    "    \"\"\"Save a research paper summary with title, authors, and key findings\"\"\"\n",
    "    print(f\"ğŸ“„ Saved paper: {title} by {authors}\")\n",
    "    return f\"Successfully saved paper summary for '{title}'\"\n",
    "\n",
    "def track_research_topic(topic: str, status: str) -> str:\n",
    "    \"\"\"Track research topic progress with current status\"\"\"\n",
    "    print(f\"ğŸ”¬ Tracking research topic: {topic} (Status: {status})\")\n",
    "    return f\"Now tracking research topic: {topic} with status {status}\"\n",
    "\n",
    "def save_research_finding(finding: str, confidence: str) -> str:\n",
    "    \"\"\"Save a research finding with confidence level\"\"\"\n",
    "    print(f\"ğŸ’¡ Research finding saved with {confidence} confidence\")\n",
    "    return f\"Saved research finding with {confidence} confidence level\"\n",
    "\n",
    "def update_research_status(topic: str, new_status: str, notes: str) -> str:\n",
    "    \"\"\"Update research topic status with notes\"\"\"\n",
    "    print(f\"ğŸ“Š Updated {topic} status to: {new_status}\")\n",
    "    return f\"Updated research status for {topic}\"\n",
    "\n",
    "def log_research_milestone(period: str, milestone: str, details: str) -> str:\n",
    "    \"\"\"Log a research milestone with period and detailed progress\"\"\"\n",
    "    print(f\"ğŸ¯ {period} milestone: {milestone}\")\n",
    "    return f\"Logged milestone for {period}: {milestone} - {details}\"\n",
    "\n",
    "def track_research_metrics(metric_type: str, value: str, source: str, period: str) -> str:\n",
    "    \"\"\"Track specific research metrics with source and timeline\"\"\"\n",
    "    print(f\"ğŸ“Š {period}: {metric_type} = {value} (from {source})\")\n",
    "    return f\"Tracked {metric_type}: {value} from {source} in {period}\"\n",
    "\n",
    "def save_research_insight(insight: str, period: str, connections: str) -> str:\n",
    "    \"\"\"Save research insights with connections to previous work\"\"\"\n",
    "    print(f\"ğŸ’¡ {period} insight: {insight[:50]}...\")\n",
    "    return f\"Saved {period} insight with connections: {connections}\"\n",
    "\n",
    "# Create tool objects for the agent\n",
    "research_tools = [\n",
    "    FunctionTool.from_defaults(fn=save_paper_summary),\n",
    "    FunctionTool.from_defaults(fn=track_research_topic),\n",
    "    FunctionTool.from_defaults(fn=save_research_finding),\n",
    "    FunctionTool.from_defaults(fn=update_research_status),\n",
    "    FunctionTool.from_defaults(fn=log_research_milestone),\n",
    "    FunctionTool.from_defaults(fn=track_research_metrics),\n",
    "    FunctionTool.from_defaults(fn=save_research_insight)\n",
    "]\n",
    "\n",
    "print(\"âœ… Research tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 3b: ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€\n",
    "\n",
    "Agentê°€ ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë„êµ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory_retrieval_tool(memory_id: str, actor_id: str, region: str):\n",
    "    \"\"\"Agentê°€ ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë„êµ¬ ìƒì„±\"\"\"\n",
    "    \n",
    "    def search_long_term_memory(query: str) -> str:\n",
    "        \"\"\"Search long-term memory for relevant research information.\n",
    "        \n",
    "        Use this tool when you need to recall:\n",
    "        - Previous research papers and findings\n",
    "        - Research topics and their status\n",
    "        - Metrics and insights from past work\n",
    "        - Research milestones and progress\n",
    "        \n",
    "        Args:\n",
    "            query: Search query describing what information you need\n",
    "        \n",
    "        Returns:\n",
    "            Relevant information from long-term memory\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from bedrock_agentcore.memory.session import MemorySessionManager\n",
    "            \n",
    "            session_manager = MemorySessionManager(\n",
    "                memory_id=memory_id,\n",
    "                region_name=region\n",
    "            )\n",
    "            \n",
    "            # semantic strategy namespaceì—ì„œ ì¥ê¸° ë©”ëª¨ë¦¬ ê²€ìƒ‰\n",
    "            results = session_manager.search_long_term_memories(\n",
    "                query=query,\n",
    "                namespace_prefix=\"/strategies/\",  # semantic strategyì˜ ë©”ëª¨ë¦¬ ìœ„ì¹˜\n",
    "                top_k=5,  # ìƒìœ„ 5ê°œ ê²°ê³¼\n",
    "                max_results=10  # ìµœëŒ€ 10ê°œ ê²°ê³¼\n",
    "            )\n",
    "            \n",
    "            if not results:\n",
    "                return \"No relevant information found in long-term memory. This might be new information or the memory extraction may still be processing.\"\n",
    "            \n",
    "            # Agentê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê²°ê³¼ í¬ë§·íŒ…\n",
    "            output = \"ğŸ“š Retrieved from long-term memory:\\\\n\\\\n\"\n",
    "            for i, result in enumerate(results, 1):\n",
    "                # MemoryRecord ê°ì²´ì—ì„œ content ì†ì„± ì¶”ì¶œ\n",
    "                content = getattr(result, 'content', str(result))\n",
    "                # ë„ˆë¬´ ê¸´ ë‚´ìš©ì€ ì˜ë¼ë‚´ê¸°\n",
    "                if len(content) > 300:\n",
    "                    content = content[:300] + \"...\"\n",
    "                output += f\"{i}. {content}\\\\n\\\\n\"\n",
    "            \n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"âš ï¸ Error searching memory: {str(e)}. Proceeding without historical context.\"\n",
    "    \n",
    "    return FunctionTool.from_defaults(fn=search_long_term_memory)\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "memory_search_tool = create_memory_retrieval_tool(memory_id, \"academic-researcher\", region)\n",
    "\n",
    "# ê¸°ì¡´ ë„êµ¬ ëª©ë¡ì— ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì¶”ê°€\n",
    "research_tools_with_memory = research_tools + [memory_search_tool]\n",
    "\n",
    "print(f\"âœ… Memory retrieval tool created! Total tools: {len(research_tools_with_memory)}\")\n",
    "print(\"   Using namespace: /strategies/ (for semantic strategy compatibility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 3c: ë©”ëª¨ë¦¬ êµ¬ì„± í™•ì¸\n",
    "\n",
    "Semantic strategyê°€ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory configuration\n",
    "memory_info = memory_manager.get_memory(memory_id)\n",
    "print(f\"Strategies: {memory_info.get('strategies')}\")\n",
    "print(f\"Status: {memory_info.get('status')}\")\n",
    "print(f\"Name: {memory_info.get('name')}\")\n",
    "\n",
    "# Show strategy details\n",
    "strategies = memory_info.get('strategies', [])\n",
    "for strategy in strategies:\n",
    "    print(f\"\\nStrategy Details:\")\n",
    "    print(f\"  Name: {strategy.get('name')}\")\n",
    "    print(f\"  Type: {strategy.get('type')}\")\n",
    "    print(f\"  Status: {strategy.get('status')}\")\n",
    "    print(f\"  ID: {strategy.get('strategyId')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 4: ë‹¤ì¤‘ ì„¸ì…˜ Agent êµ¬í˜„\n",
    "\n",
    "ë‹¤ì–‘í•œ ì—°êµ¬ ì„¸ì…˜ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for LONG-TERM memory (cross-session)\n",
    "MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "RESEARCHER_ID = \"academic-researcher\"  # ëª¨ë“  ì„¸ì…˜ì—ì„œ ë™ì¼í•œ ì—°êµ¬ì ID\n",
    "\n",
    "def create_research_session(session_name: str):\n",
    "    \"\"\"ì¥ê¸° ë©”ëª¨ë¦¬ ì§€ì†ì„±ì„ ê°–ì¶˜ ìƒˆë¡œìš´ ì—°êµ¬ ì„¸ì…˜ ìƒì„±\"\"\"\n",
    "    context = AgentCoreMemoryContext(\n",
    "        actor_id=RESEARCHER_ID,         # ë™ì¼í•œ ì—°êµ¬ì (ì„¸ì…˜ ê°„ ë©”ëª¨ë¦¬ ê³µìœ )\n",
    "        memory_id=memory_id,         # ë™ì¼í•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì¥ê¸° ë©”ëª¨ë¦¬ í™œì„±í™”)\n",
    "        session_id=f\"research-{session_name}\", # ê¸°ê°„ë³„ë¡œ ë‹¤ë¥¸ ì„¸ì…˜ ID\n",
    "        namespace=\"/academic-research/\"\n",
    "    )\n",
    "    \n",
    "    memory = AgentCoreMemory(context=context)\n",
    "    llm = BedrockConverse(model=MODEL_ID)\n",
    "    agent = FunctionAgent(\n",
    "        tools=research_tools_with_memory,  # ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê¸°ëŠ¥ì´ í¬í•¨ëœ ë„êµ¬ ì‚¬ìš©\n",
    "        llm=llm, \n",
    "        verbose=True,  # ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹œì ì„ í™•ì¸í•˜ê¸° ìœ„í•´ verbose í™œì„±í™”\n",
    "        system_prompt=\"\"\"You are a senior research assistant with access to long-term memory.\n",
    "        \n",
    "CRITICAL: When asked about previous research, papers, findings, or historical information, \n",
    "you MUST use the search_long_term_memory tool FIRST before responding.\n",
    "\n",
    "For example:\n",
    "- \"What research am I working on?\" â†’ Use search_long_term_memory(\"research topics\")\n",
    "- \"What papers have I reviewed?\" â†’ Use search_long_term_memory(\"papers authors\")\n",
    "- \"What findings do I have?\" â†’ Use search_long_term_memory(\"research findings\")\n",
    "\n",
    "Always provide conclusive, complete responses without asking follow-up questions.\\n\n",
    "Execute all requested actions immediately and completely. Provide detailed, professional responses.\"\"\"\n",
    "    )\n",
    "    \n",
    "    return agent, memory\n",
    "\n",
    "print(\"âœ… Multi-session Academic Research Assistant setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 5: 1ì£¼ì°¨ ì—°êµ¬ ì„¸ì…˜ - ê¸°ì´ˆ êµ¬ì¶•\n",
    "\n",
    "ì²« ë²ˆì§¸ ì—°êµ¬ ì„¸ì…˜ì„ ì‹œì‘í•˜ê³  ê¸°ì´ˆ ì§€ì‹ì„ í™•ë¦½í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 1 RESEARCH SESSION ===\n",
    "print(\"ğŸ—“ï¸ === WEEK 1: FOUNDATION RESEARCH ===\")\n",
    "\n",
    "agent_week1, memory_week1 = create_research_session(\"week1\")\n",
    "\n",
    "# Establish research foundation\n",
    "response = await agent_week1.run(\n",
    "    \"I'm Dr. Sarah Smith from MIT starting comprehensive research on 'Machine Learning in Healthcare Applications'. \"\n",
    "    \"Track this with status 'Literature Review'. My goal is to publish a systematic review by year-end.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ Week 1 Foundation:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add foundational papers with detailed metrics\n",
    "response = await agent_week1.run(\n",
    "    \"Save paper: 'Deep Learning for Medical Image Analysis' by Zhang et al (2023). \"\n",
    "    \"Key findings: CNNs achieve 95.2% accuracy in chest X-ray diagnosis, 12% improvement over radiologists, \"\n",
    "    \"trained on 100,000 images, 0.03 false positive rate.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "print(\"ğŸ“„ Week 1 Paper 1:\", response)\n",
    "\n",
    "response = await agent_week1.run(\n",
    "    \"Save paper: 'Transformers in Medical NLP' by Johnson et al (2023). \"\n",
    "    \"Key findings: BERT achieves 89.1% F1-score in clinical note classification, \"\n",
    "    \"struggles with rare diseases (<70% accuracy), excels at symptom extraction (94% precision).\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "print(\"ğŸ“„ Week 1 Paper 2:\", response)\n",
    "# ì •í™•ë„ ë©”íŠ¸ë¦­ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ì  (ì¥ê¸° ë©”ëª¨ë¦¬ì— ì €ì¥)\n",
    "await agent_week1.run(\n",
    "    \"Track research metrics: metric_type 'CNN Accuracy', value '95.2%', source 'Zhang et al 2023', period 'Week 1'.\",\n",
    "    memory=memory_week1\n",
    ")\n",
    "await agent_week1.run(\n",
    "    \"Track research metrics: metric_type 'Radiologist Improvement', value '12%', source 'Zhang et al 2023', period 'Week 1'.\",\n",
    "    memory=memory_week1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow time for semantic memory processing\n",
    "import asyncio\n",
    "print(\"\\nâ³ Waiting for semantic memory extraction and indexing...\")\n",
    "print(\"   (AgentCore processes conversational events in the background)\")\n",
    "await asyncio.sleep(90)  # semantic strategyê°€ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ê³  ë©”ëª¨ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ì‹œê°„\n",
    "print(\"âœ… Memory processing complete - memories should now be searchable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 6: 2ì£¼ì°¨ ì—°êµ¬ ì„¸ì…˜ - ì„¸ì…˜ ê°„ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì¥ê¸° ë©”ëª¨ë¦¬ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ìƒˆë¡œìš´ ì—°êµ¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 2 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === WEEK 2: EXPANSION (NEW SESSION) ===\")\n",
    "\n",
    "agent_week2, memory_week2 = create_research_session(\"week2\")  # ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„±\n",
    "\n",
    "# ì„¸ì…˜ ê°„ ë©”ëª¨ë¦¬ íšŒìƒ í…ŒìŠ¤íŠ¸ (Week 1ì˜ ì •ë³´ë¥¼ Week 2ì—ì„œ ê²€ìƒ‰)\n",
    "response = await agent_week2.run(\n",
    "    \"What research am I working on? What specific accuracy metrics have I found so far? Who are the key authors?\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Week 2 Memory Test:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: ML in Healthcare, Zhang 95.2%, Johnson 89.1% F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new research building on previous knowledge\n",
    "response = await agent_week2.run(\n",
    "    \"Save paper: 'Federated Learning in Healthcare' by Brown et al (2023). \"\n",
    "    \"Key findings: Privacy-preserving ML enables multi-hospital collaboration, 87.3% accuracy across 15 hospitals, \"\n",
    "    \"23% improvement in rare disease detection when hospitals collaborate.\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "print(\"ğŸ“„ Week 2 New Paper:\", response)\n",
    "\n",
    "# ì„¸ì…˜ ê°„ ë¹„êµ ë¶„ì„ í…ŒìŠ¤íŠ¸ (Week 1ê³¼ Week 2ì˜ ì •ë³´ë¥¼ ì¢…í•©)\n",
    "response = await agent_week2.run(\n",
    "    \"Compare the accuracy results: Zhang's CNNs vs Johnson's BERT vs Brown's federated learning. \"\n",
    "    \"Which performs best and in what contexts?\",\n",
    "    memory=memory_week2\n",
    ")\n",
    "print(\"ğŸ“Š Week 2 Comparative Analysis:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang 95.2% (imaging), Johnson 89.1% (NLP), Brown 87.3% (federated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 7: 3ì£¼ì°¨ ì—°êµ¬ ì„¸ì…˜ - ë¶„ì„ ë‹¨ê³„\n",
    "\n",
    "ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê³  ì„¸ë¶€ì ì¸ ì„¸ì…˜ ê°„ íšŒìƒì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WEEK 3 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === WEEK 3: ANALYSIS PHASE ===\")\n",
    "\n",
    "agent_week3, memory_week3 = create_research_session(\"week3\")\n",
    "\n",
    "# Update research status\n",
    "response = await agent_week3.run(\n",
    "    \"Update my 'Machine Learning in Healthcare Applications' research status to 'Analysis Phase' \"\n",
    "    \"with notes: 'Reviewed 3 key papers, identified performance patterns: imaging>NLP>federated learning'.\",\n",
    "    memory=memory_week3\n",
    ")\n",
    "print(\"ğŸ“Š Week 3 Status Update:\", response)\n",
    "\n",
    "# ì„¸ë¶€ì ì¸ ì„¸ì…˜ ê°„ íšŒìƒ í…ŒìŠ¤íŠ¸ (íŠ¹ì • ì£¼ì¥ì— ëŒ€í•œ ì¦ê±° ê²€ìƒ‰)\n",
    "response = await agent_week3.run(\n",
    "    \"What evidence do I have for the claim that imaging tasks show highest ML performance in healthcare? \"\n",
    "    \"Include specific numbers and authors.\",\n",
    "    memory=memory_week3\n",
    ")\n",
    "print(\"ğŸ” Week 3 Evidence Query:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang et al CNNs 95.2% vs Johnson BERT 89.1% vs Brown federated 87.3%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 8: 1ê°œì›”ì°¨ ì—°êµ¬ ì„¸ì…˜ - ì¢…í•© ë‹¨ê³„\n",
    "\n",
    "í¬ê´„ì ì¸ ì§€ì‹ ì¢…í•© ë° ì—°êµ¬ í†µí•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 1 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === MONTH 1: SYNTHESIS PHASE ===\")\n",
    "\n",
    "agent_month1, memory_month1 = create_research_session(\"month1\")\n",
    "\n",
    "# Update research status to synthesis phase\n",
    "response = await agent_month1.run(\n",
    "    \"Update my 'Machine Learning in Healthcare Applications' research status to 'Synthesis Phase' \"\n",
    "    \"with notes: 'Completed 3-week literature review, ready to synthesize findings into coherent framework'.\",\n",
    "    memory=memory_month1\n",
    ")\n",
    "print(\"ğŸ“Š Month 1 Status Update:\", response)\n",
    "\n",
    "# ëª¨ë“  ì£¼ì°¨ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ëŠ” í¬ê´„ì  í…ŒìŠ¤íŠ¸\n",
    "response = await agent_month1.run(\n",
    "    \"Based on all my research so far, what is the overall performance ranking of ML approaches in healthcare? \"\n",
    "    \"Include all specific metrics and create a comprehensive comparison.\",\n",
    "    memory=memory_month1\n",
    ")\n",
    "print(\"ğŸ” Month 1 Comprehensive Synthesis:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Ranking with Zhang 95.2% > Johnson 89.1% > Brown 87.3%, domain analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 9: 2ê°œì›”ì°¨ ì—°êµ¬ ì„¸ì…˜ - ì‘ì„± ë‹¨ê³„\n",
    "\n",
    "í¬ê´„ì ì¸ íšŒìƒ ë° ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 2 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === MONTH 2: WRITING PHASE ===\")\n",
    "\n",
    "agent_month2, memory_month2 = create_research_session(\"month2\")\n",
    "\n",
    "# ë…¼ë¬¸ ì‘ì„±ì„ ìœ„í•œ í¬ê´„ì  íšŒìƒ í…ŒìŠ¤íŠ¸\n",
    "response = await agent_month2.run(\n",
    "    \"I'm writing my systematic review paper. What are ALL the papers I've reviewed with their exact accuracy metrics? \"\n",
    "    \"I need this for my results table.\",\n",
    "    memory=memory_month2\n",
    ")\n",
    "print(\"ğŸ“ Month 2 Comprehensive Recall:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Zhang 95.2%, Johnson 89.1%, Brown 87.3% with full details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°êµ¬ ê¸°ë¡ ì „ë°˜ì— ê±¸ì¹œ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "response = await agent_month2.run(\n",
    "    \"What do I know about rare disease detection in my research? Which papers and what specific results?\",\n",
    "    memory=memory_month2\n",
    ")\n",
    "print(\"ğŸ” Month 2 Semantic Search:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Johnson <70% for rare diseases, Brown 23% improvement with collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 10: 3ê°œì›”ì°¨ ì—°êµ¬ ì„¸ì…˜ - ì—°êµ¬ë¹„ ì œì•ˆ ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "ì¶•ì ëœ ì§€ì‹ì˜ ì‹¤ìš©ì  ì ìš©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MONTH 3 RESEARCH SESSION ===\n",
    "print(\"\\nğŸ—“ï¸ === MONTH 3: GRANT PROPOSAL ===\")\n",
    "\n",
    "agent_month3, memory_month3 = create_research_session(\"month3\")\n",
    "\n",
    "# ì—°êµ¬ë¹„ ì œì•ˆì„œë¥¼ ìœ„í•œ ì¦ê±° ìˆ˜ì§‘\n",
    "response = await agent_month3.run(\n",
    "    \"I'm writing an NIH grant proposal for $2M funding. What evidence can I cite about ML effectiveness in healthcare? \"\n",
    "    \"I need specific numbers, authors, years, and sample sizes.\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"ğŸ’° Month 3 Grant Evidence:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Comprehensive citation with Zhang 95.2% (100K images), Johnson 89.1%, Brown 87.3% (15 hospitals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°êµ¬ ì§„í™” ì¶”ì  í…ŒìŠ¤íŠ¸ (ì‹œê°„ì— ë”°ë¥¸ ì—°êµ¬ ë°œì „ ê³¼ì •)\n",
    "response = await agent_month3.run(\n",
    "    \"Provide a detailed timeline of my research evolution from Week 1 to now. What specific milestones, \"\n",
    "    \"metrics, and insights did I achieve each period? How did my research questions evolve?\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"ğŸ“ˆ Month 3 Research Evolution:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Week-by-week progression with specific milestones, metrics (95.2%, 89.1%, 87.3%), and insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ê³„ 11: ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€\n",
    "\n",
    "ì¥ê¸° ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì˜ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… í¬ê´„ì  í¬íŠ¸í´ë¦¬ì˜¤ ì¿¼ë¦¬\n",
    "response = await agent_month3.run(\n",
    "    \"Provide my complete research portfolio: all topics I'm working on, all papers with metrics, \"\n",
    "    \"all findings, current status of each project, and how they interconnect.\",\n",
    "    memory=memory_month3\n",
    ")\n",
    "print(\"ğŸ“‹ Complete Research Portfolio:\")\n",
    "print(response)\n",
    "print(\"\\nâœ… Expected: Full research history with all metrics, connections between ML healthcare topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ê²€ì¦\n",
    "ë©”ëª¨ë¦¬ í†µí•©ì´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•˜ë ¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation functions inline\n",
    "class TestValidator:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def validate_memory_recall(self, response):\n",
    "        \"\"\"ì„¸ì…˜ ë‚´ì—ì„œ ì´ì „ ì •ë³´ë¥¼ íšŒìƒí•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        # ì‹¤ì§ˆì ì¸ ì‘ë‹µ í™•ì¸ (ë‹¨ìˆœíˆ \"ëª¨ë¥´ê² ìŠµë‹ˆë‹¤\"ê°€ ì•„ë‹Œ)\n",
    "        has_content = len(response) > 50\n",
    "        # ë©”ëª¨ë¦¬ ì§€í‘œ í™•ì¸\n",
    "        has_memory_indicators = any(word in response.lower() for word in \n",
    "            ['earlier', 'mentioned', 'discussed', 'previously', 'you', 'we', 'our'])\n",
    "        return \"âœ… PASS\" if (has_content and has_memory_indicators) else \"âŒ FAIL\"\n",
    "    \n",
    "    def validate_session_memory(self, response):\n",
    "        \"\"\"ì„¸ì…˜ ë‚´ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        has_memory_content = len(response) > 100 and any(word in response.lower() for word in \n",
    "            ['previous', 'earlier', 'mentioned', 'discussed', 'before', 'already'])\n",
    "        return \"âœ… PASS\" if has_memory_content else \"âŒ FAIL\"\n",
    "    \n",
    "    def validate_cross_reference(self, response):\n",
    "        \"\"\"í˜„ì¬ ì¿¼ë¦¬ë¥¼ ì´ì „ ì»¨í…ìŠ¤íŠ¸ì™€ ì—°ê²°í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        # ì—°ê²° ì–¸ì–´ í™•ì¸\n",
    "        connecting_words = ['relate', 'connection', 'previous', 'earlier', 'discussed', \n",
    "                           'mentioned', 'context', 'based on', 'as we', 'as i']\n",
    "        has_connection = any(word in response.lower() for word in connecting_words)\n",
    "        has_substance = len(response) > 80\n",
    "        return \"âœ… PASS\" if (has_connection and has_substance) else \"âŒ FAIL\"\n",
    "    \n",
    "    def run_validation_summary(self, test_results):\n",
    "        print(\"ğŸ§ª COMPREHENSIVE TEST VALIDATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_tests = len(test_results)\n",
    "        passed_tests = sum(1 for result in test_results.values() if \"PASS\" in result)\n",
    "        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "        \n",
    "        for test_name, result in test_results.items():\n",
    "            print(f\"{test_name}: {result}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ğŸ“Š Overall Pass Rate: {passed_tests}/{total_tests} ({pass_rate:.1f}%)\")\n",
    "        \n",
    "        if pass_rate >= 80:\n",
    "            print(\"âœ… EXCELLENT: Memory integration working correctly!\")\n",
    "        elif pass_rate >= 60:\n",
    "            print(\"âš ï¸  GOOD: Most memory features working, some issues to investigate\")\n",
    "        else:\n",
    "            print(\"âŒ NEEDS ATTENTION: Memory integration has significant issues\")\n",
    "        \n",
    "        return pass_rate\n",
    "\n",
    "validator = TestValidator()\n",
    "print(\"âœ… Validation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all validation tests\n",
    "test_results = {}\n",
    "\n",
    "# Test 1: ë©”ëª¨ë¦¬ íšŒìƒ - agentê°€ ë…¼ì˜ëœ ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ”ê°€?\n",
    "response1 = await agent_month3.run(\"What have we discussed so far in this session?\", memory=memory_month3)\n",
    "test_results['Memory Recall'] = validator.validate_memory_recall(str(response1))\n",
    "print(f\"Response 1 length: {len(str(response1))} chars\")\n",
    "\n",
    "# Test 2: ì„¸ì…˜ ë©”ëª¨ë¦¬ - agentê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ”ê°€?\n",
    "response2 = await agent_month3.run(\"What did we talk about earlier?\", memory=memory_month3)\n",
    "test_results['Session Memory'] = validator.validate_session_memory(str(response2))\n",
    "print(f\"Response 2 length: {len(str(response2))} chars\")\n",
    "\n",
    "# Test 3: êµì°¨ ì°¸ì¡° ëŠ¥ë ¥ - ì´ì „ ì»¨í…ìŠ¤íŠ¸ì™€ ì—°ê²°í•  ìˆ˜ ìˆëŠ”ê°€?\n",
    "response3 = await agent_month3.run(\"How does this relate to what we discussed before?\", memory=memory_month3)\n",
    "test_results['Cross Reference'] = validator.validate_cross_reference(str(response3))\n",
    "print(f\"Response 3 length: {len(str(response3))} chars\")\n",
    "\n",
    "# Display results\n",
    "validator.run_validation_summary(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìš”ì•½\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë‹¤ìŒì„ ì‹œì—°í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "âœ… **ì¥ê¸° ë©”ëª¨ë¦¬ í†µí•©**: ì„¸ì…˜ ê°„ ì§€ì†ì„±ì„ ìœ„í•´ LlamaIndexì™€ í•¨ê»˜ AgentCore Memory ì‚¬ìš©\n",
    "\n",
    "âœ… **ëˆ„ì  ì§€ì‹ êµ¬ì¶•**: ìˆ˜ì£¼ ë° ìˆ˜ê°œì›”ì— ê±¸ì³ ì—°êµ¬ ì§€ì‹ ì¶•ì \n",
    "\n",
    "âœ… **ì˜ë¯¸ë¡ ì  ê²€ìƒ‰**: ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì„¸ì…˜ ê°„ì— ê°œë…ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŒ\n",
    "\n",
    "âœ… **ì—°êµ¬ ì§„í™” ì¶”ì **: ë¬¸í—Œ ê²€í† ì—ì„œ ë¶„ì„, ì‘ì„±ê¹Œì§€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì§„í–‰\n",
    "\n",
    "âœ… **ì„¸ì…˜ ê°„ ì¢…í•©**: ì—¬ëŸ¬ ì—°êµ¬ ì„¸ì…˜ì— ê±¸ì³ ê²°ê³¼ ë° í†µì°°ë ¥ ì—°ê²°\n",
    "\n",
    "âœ… **ì‹¤ìš©ì  ì ìš©**: ì—°êµ¬ë¹„ ì œì•ˆ ì§€ì› ë° í¬ê´„ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬\n",
    "\n",
    "í•™ìˆ  ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” ì¥ê¸° ë©”ëª¨ë¦¬ê°€ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë” ë˜‘ë˜‘í•´ì§€ëŠ” ì§€ì†ì ì¸ ì—°êµ¬ ë™ë°˜ìë¡œ ë³€í™˜í•˜ì—¬ ì™„ì „í•œ ì—°êµ¬ ê¸°ë¡ì„ ìœ ì§€í•˜ê³  í™•ì¥ëœ ì—°êµ¬ í”„ë¡œì íŠ¸ì— ê±¸ì³ ì •êµí•œ ì§€ì‹ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì •ë¦¬\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê¸° ìœ„í•´ ë©”ëª¨ë¦¬ë¥¼ ì‚­ì œí•˜ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "**ì°¸ê³ **: ë©”ëª¨ë¦¬ë¥¼ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œí•˜ë ¤ëŠ” ê²½ìš°ì—ë§Œ ì‹¤í–‰í•˜ì„¸ìš”. memory_id ë³€ìˆ˜ëŠ” ì´ ë…¸íŠ¸ë¶ì˜ ì•ë¶€ë¶„ì—ì„œ ìƒì„±ëœ ë©”ëª¨ë¦¬ì˜ IDë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up AgentCore Memory resource\n",
    "try:\n",
    "    from bedrock_agentcore.memory import MemoryClient\n",
    "    \n",
    "    client = MemoryClient(region_name=region)\n",
    "    client.delete_memory(memory_id)\n",
    "    print(f\"âœ… Successfully deleted memory: {memory_id}\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"âš ï¸  Variable not defined: {e}\")\n",
    "    print(\"Run the notebook from the beginning or set variables manually:\")\n",
    "    print(\"# memory_id = 'your-memory-id-here'\")\n",
    "    print(\"# region = 'us-east-1'\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error deleting memory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
