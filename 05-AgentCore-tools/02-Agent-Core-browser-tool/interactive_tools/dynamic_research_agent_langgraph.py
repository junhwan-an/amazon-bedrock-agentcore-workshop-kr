"""
Bedrock-AgentCore Code Interpreterë¥¼ ì‚¬ìš©í•œ ë™ì  ì—°êµ¬ Agent
ë‹¨ìˆœí™”ëœ ì•„í‚¤í…ì²˜ì™€ ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨
"""

import asyncio
import json
import os
from typing import Dict, List, TypedDict, Optional, Any, Annotated
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_aws import ChatBedrockConverse
from bedrock_agentcore.tools.code_interpreter_client import CodeInterpreter
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.syntax import Syntax

console = Console()

# Agent ìƒíƒœ ì •ì˜
class AgentState(TypedDict):
    """ì ì ˆí•œ ì–´ë…¸í…Œì´ì…˜ì„ ê°€ì§„ ì—°êµ¬ Agentì˜ ìƒíƒœ"""
    messages: Annotated[List, "append"]  # LangGraphì—ì„œ ë©”ì‹œì§€ë¥¼ ëˆ„ì í•˜ê¸° ìœ„í•œ ì–´ë…¸í…Œì´ì…˜
    research_query: str
    code_session_id: Optional[str]
    research_data: Dict[str, any]
    completed_tasks: List[str]
    errors: List[str]


class ResearchAgent:
    """ê°„ì†Œí™”ëœ ì—°êµ¬ Agent"""
    
    def __init__(self, region: str = "us-west-2", model: str = "global.anthropic.claude-haiku-4-5-20251001-v1:0"):
        self.region = region
        self.model = model
        self.llm = ChatBedrockConverse(
            model=model,
            region_name=region
        )
        
        console.print("[cyan]Initializing Bedrock-AgentCore Tools...[/cyan]")
        
        # Code Interpreter ì„¸ì…˜ ì´ˆê¸°í™” (ìƒŒë“œë°•ìŠ¤ í™˜ê²½ ìƒì„±)
        self.code_client = CodeInterpreter(region)
        self.code_session_id = self.code_client.start()
        console.print(f"âœ… Code Interpreter session: {self.code_session_id}")
        
        # ìž‘ì—… í™˜ê²½ ì„¤ì •
        self._setup_working_environment()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()
    
    def cleanup(self):
        console.print("\n[yellow]Cleaning up...[/yellow]")
        if self.code_client:
            self.code_client.stop()
    
    def _setup_working_environment(self):
        """ìƒì„¸í•œ í”¼ë“œë°±ê³¼ í•¨ê»˜ code interpreterì—ì„œ ìž‘ì—… í™˜ê²½ ì„¤ì •"""
        setup_code = """
import os
import sys
import matplotlib
matplotlib.use('Agg')  # ë¹„ì¸í„°ëž™í‹°ë¸Œ ë°±ì—”ë“œ ì‚¬ìš©

# í˜„ìž¬ ìž‘ì—… ë””ë ‰í† ë¦¬ ì¶œë ¥
print(f"Current working directory: {os.getcwd()}")
print(f"Python version: {sys.version}")

# ìƒì„¸í•œ í”¼ë“œë°±ê³¼ í•¨ê»˜ ë””ë ‰í† ë¦¬ ìƒì„±
try:
    os.makedirs('data', exist_ok=True)
    print("âœ“ Created 'data' directory")
    os.makedirs('visualizations', exist_ok=True)
    print("âœ“ Created 'visualizations' directory")
    os.makedirs('reports', exist_ok=True)
    print("âœ“ Created 'reports' directory")
    print("Environment setup complete.")
except Exception as e:
    print(f"Error creating directories: {e}")
    
# íŒŒì¼ ì“°ê¸° í…ŒìŠ¤íŠ¸
try:
    with open('data/test_file.txt', 'w') as f:
        f.write('Test file writing capability')
    print("âœ“ Successfully tested file writing")
except Exception as e:
    print(f"Error writing test file: {e}")

# í™•ì¸ì„ ìœ„í•´ ë””ë ‰í† ë¦¬ ë‚˜ì—´
print("\\nDirectory structure:")
for root, dirs, files in os.walk('.'):
    level = root.count(os.sep)
    indent = ' ' * 4 * level
    print(f"{indent}{os.path.basename(root) or '.'}/")
    for file in files:
        print(f"{indent}    {file}")
"""
        result = self.code_client.invoke("executeCode", {
            "code": setup_code,
            "language": "python",
            "clearContext": False
        })
        console.print(self._extract_output(result))
    
    def _refresh_file_list(self):
        """ìƒŒë“œë°•ìŠ¤ì—ì„œ ì—…ë°ì´íŠ¸ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        result = self.code_client.invoke("listFiles", {"path": ""})
        return self._extract_output(result).strip().split('\n') if self._extract_output(result).strip() else []
    
    def _extract_output(self, result: Dict) -> str:
        """ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ì—ì„œ ì¶œë ¥ ì¶”ì¶œ"""
        # structuredContent í˜•ì‹ ì²˜ë¦¬ (stdout/stderr ë¶„ë¦¬)
        if "structuredContent" in result:
            stdout = result["structuredContent"].get("stdout", "")
            stderr = result["structuredContent"].get("stderr", "")
            return stdout + (f"\nSTDERR: {stderr}" if stderr else "")
        
        # content ë°°ì—´ í˜•ì‹ ì²˜ë¦¬
        output_parts = []
        if "content" in result:
            for item in result["content"]:
                if item.get("type") == "text":
                    output_parts.append(item.get("text", ""))
        return "\n".join(output_parts)
    
    def _extract_code_block(self, text: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì„ í¬í•¨í•  ìˆ˜ ìžˆëŠ” í…ìŠ¤íŠ¸ì—ì„œ ì½”ë“œ ì¶”ì¶œ"""
        # ```python í˜•ì‹ì˜ ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        if "```python" in text:
            start_idx = text.find("```python") + 9
            end_idx = text.find("```", start_idx)
            if end_idx != -1:
                return text[start_idx:end_idx].strip()
        # ì–¸ì–´ ì§€ì • ì—†ëŠ” ``` í˜•ì‹ì˜ ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        elif "```" in text:
            start_idx = text.find("```") + 3
            end_idx = text.find("```", start_idx)
            if end_idx != -1:
                return text[start_idx:end_idx].strip()
        
        # ì½”ë“œ ë¸”ë¡ì„ ì°¾ì§€ ëª»í•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
        return text.strip()
    
    def execute_llm_generated_code(self, task_description: str, context: Dict = None) -> Dict[str, Any]:
        """ìž‘ì—…ì„ ìœ„í•´ LLMì´ ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•˜ë„ë¡ í•¨"""
        console.print(f"\n[bold blue]ðŸ¤– LLM generating code for:[/bold blue] {task_description}")
        
        # ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""You are working in a Python code interpreter sandbox. 
Task: {task_description}

Available context:
{json.dumps(context, indent=2) if context else 'No previous context'}

Generate Python code to accomplish this task. Be specific and include:
- All necessary imports (pandas, numpy, matplotlib, seaborn, scikit-learn, etc. are available)
- Error handling with try/except blocks
- Clear output with print statements to show progress
- Ensure visualizations have proper titles, labels, and legends
- Save outputs to appropriate directories:
  * data/ - for CSV and JSON files
  * visualizations/ - for plots and charts
  * reports/ - for text reports

Return ONLY the Python code, no explanations."""
        
        # LLMì—ì„œ ì½”ë“œ ìƒì„±
        response = self.llm.invoke([HumanMessage(content=prompt)])
        generated_code = self._extract_code_block(response.content)
        
        # ì½”ë“œ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
        code_preview = generated_code[:300] + "..." if len(generated_code) > 300 else generated_code
        console.print(Syntax(code_preview, "python"))
        
        # Code Interpreterì—ì„œ ì½”ë“œ ì‹¤í–‰
        result = self.code_client.invoke("executeCode", {
            "code": generated_code,
            "language": "python",
            "clearContext": False  # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ (ë³€ìˆ˜, import ë“±)
        })
        
        # ì¶œë ¥ ì¶”ì¶œ
        output = self._extract_output(result)
        
        # ì˜¤ë¥˜ í™•ì¸
        has_error = result.get("isError", False)
        if has_error:
            console.print(f"[red]Execution error:[/red]\n{output}")
        else:
            console.print(f"[green]âœ… Code executed successfully[/green]")
        
        # ì—…ë°ì´íŠ¸ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        files = self._refresh_file_list()
        
        return {
            "output": output,
            "error": has_error,
            "files": files
        }
    
    def create_workflow(self) -> StateGraph:
        """ëª¨ë“  ë‹¨ê³„ë¥¼ ì‹œë„í•˜ëŠ” ê°„ë‹¨í•œ ì„ í˜• ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€ (ê° ë…¸ë“œëŠ” ì—°êµ¬ì˜ í•œ ë‹¨ê³„)
        workflow.add_node("understand_query", self.understand_query)
        workflow.add_node("collect_data", self.collect_data)
        workflow.add_node("process_data", self.process_data)
        workflow.add_node("analyze_data", self.analyze_data)
        workflow.add_node("generate_insights", self.generate_insights)
        
        # ì„ í˜• í”Œë¡œìš° ì„¤ì • - ëª¨ë“  ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
        workflow.set_entry_point("understand_query")
        workflow.add_edge("understand_query", "collect_data")
        workflow.add_edge("collect_data", "process_data")
        workflow.add_edge("process_data", "analyze_data")
        workflow.add_edge("analyze_data", "generate_insights")
        workflow.add_edge("generate_insights", END)
        
        return workflow.compile()
    
    def understand_query(self, state: AgentState) -> AgentState:
        """ì‚¬ìš©ìžê°€ ì—°êµ¬í•˜ê³ ìž í•˜ëŠ” ë‚´ìš© ì´í•´"""
        console.print(f"\n[bold magenta]ðŸŽ¯ Understanding research query:[/bold magenta] {state['research_query']}")
        
        # LLMì´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ë„ë¡ í•¨
        prompt = f"""Analyze this research query: '{state['research_query']}'
        
Break it down into:
1. What specific data points need to be collected
2. What analysis techniques would be most appropriate
3. What insights are expected
4. What visualizations would be most informative

Respond in JSON format with the following structure:
{{
  "data_points": [],
  "analysis_techniques": [],
  "expected_insights": [],
  "recommended_visualizations": []
}}"""
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        understanding = response.content
        
        try:
            # JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
            json_understanding = json.loads(understanding)
            console.print("[green]Query analysis completed as structured JSON[/green]")
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
            console.print("[yellow]Could not parse response as JSON. Using raw text.[/yellow]")
            json_understanding = {"raw_analysis": understanding}
        
        # ì´í•´í•œ ë‚´ìš©ì˜ ìš”ì•½ í‘œì‹œ
        console.print("[cyan]Query Understanding:[/cyan]")
        for key, value in json_understanding.items():
            if isinstance(value, list) and value:
                console.print(f"[cyan]â€¢ {key}:[/cyan] {', '.join(value[:3])}{'...' if len(value) > 3 else ''}")
            else:
                preview = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                console.print(f"[cyan]â€¢ {key}:[/cyan] {preview}")
        
        return {
            **state,
            "research_data": {"query_understanding": json_understanding},
            "completed_tasks": ["understand_query"],
            "errors": []
        }
    
    def collect_data(self, state: AgentState) -> AgentState:
        """ì—°êµ¬ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘"""
        console.print("\n[bold magenta]ðŸ“Š Collecting data...[/bold magenta]")
        
        # í•©ì„± ë°ì´í„° ìƒì„± (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” API í˜¸ì¶œì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
        synthetic_data_code = """
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random
import os
import matplotlib.pyplot as plt
import seaborn as sns

# ë””ë ‰í† ë¦¬ê°€ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸
os.makedirs('data', exist_ok=True)
os.makedirs('visualizations', exist_ok=True)

# ëžœë¤ ì‹œë“œ ì„¤ì • (ìž¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´)
np.random.seed(42)

# ê³ ê° ID
n_customers = 1000
customer_ids = [f'CUST{i:05d}' for i in range(n_customers)]

# ë‚ ì§œ ë²”ìœ„ - ìµœê·¼ 2ë…„
end_date = datetime.now()
start_date = end_date - timedelta(days=730)
dates = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]

# êµ¬ë§¤ ë°ì´í„° ìƒì„± - ê³ ê°ë‹¹ ì—¬ëŸ¬ êµ¬ë§¤
purchases = []
for cust_id in customer_ids:
    # ëžœë¤ êµ¬ë§¤ íšŸìˆ˜ (í¬ì•„ì†¡ ë¶„í¬ ì‚¬ìš©)
    n_purchases = np.random.poisson(3)  
    for _ in range(n_purchases):
        purchase_date = np.random.choice(dates)
        # ìµœê·¼ ëª‡ ê°œì›” ë™ì•ˆ êµ¬ë§¤ í™•ë¥ ì´ ë” ë†’ìŒ
        days_ago = (end_date - purchase_date).days
        if days_ago > 365 and random.random() < 0.5:
            continue  # ì¼ë¶€ ì˜¤ëž˜ëœ êµ¬ë§¤ ê±´ë„ˆë›°ê¸°
            
        purchases.append({
            'customer_id': cust_id,
            'purchase_date': purchase_date,
            'product_category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Beauty', 'Food', 'Sports']),
            'amount': round(np.random.gamma(shape=2, scale=25), 2),
            'satisfaction_score': np.random.choice(range(1, 11), p=[0.01, 0.02, 0.03, 0.05, 0.09, 0.15, 0.25, 0.2, 0.1, 0.1]),
            'delivery_days': np.random.choice(range(1, 10)),
            'is_return': np.random.choice([0, 1], p=[0.95, 0.05])
        })

# DataFrameìœ¼ë¡œ ë³€í™˜
df = pd.DataFrame(purchases)

# ë” ë§Žì€ íŠ¹ì„± ì¶”ê°€
df['is_repeat_purchase'] = df.groupby('customer_id')['purchase_date'].rank(method='first') > 1
df['is_repeat_purchase'] = df['is_repeat_purchase'].astype(int)

# ê³ ê° ìƒì•  ê°€ì¹˜ ê³„ì‚°
customer_stats = df.groupby('customer_id').agg(
    total_spent=('amount', 'sum'),
    avg_satisfaction=('satisfaction_score', 'mean'),
    purchase_count=('purchase_date', 'count')
).reset_index()

# ë°ì´í„° íŒŒì¼ ì €ìž¥
df.to_csv('data/research_data.csv', index=False)
customer_stats.to_csv('data/customer_stats.csv', index=False)

# ê°„ë‹¨í•œ ì‹œê°í™” ìƒì„±
plt.figure(figsize=(10, 6))
sns.histplot(df['satisfaction_score'], kde=True, bins=10)
plt.title('Distribution of Customer Satisfaction Scores')
plt.xlabel('Satisfaction Score')
plt.ylabel('Count')
plt.savefig('visualizations/satisfaction_distribution.png', dpi=300)

print(f"Created dataset with {len(df)} purchases from {n_customers} customers")
print(f"Data saved to data/research_data.csv")
print(f"Customer stats saved to data/customer_stats.csv")
print(f"Basic visualization saved to visualizations/satisfaction_distribution.png")
print("\\nFirst 5 rows of data:")
print(df.head())
print("\\nSummary statistics:")
print(df.describe())
"""
        
        # ë°ì´í„° ìƒì„± ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰
        result = self.code_client.invoke("executeCode", {
            "code": synthetic_data_code,
            "language": "python",
            "clearContext": False
        })
        
        output = self._extract_output(result)
        console.print(output)
        
        # ì˜¤ë¥˜ê°€ ìžˆëŠ”ì§€ í™•ì¸
        errors = state["errors"]
        if result.get("isError", False):
            errors.append("Error generating synthetic data")
        
        return {
            **state,
            "research_data": {
                **state["research_data"],
                "data_collection_output": output
            },
            "completed_tasks": state["completed_tasks"] + ["collect_data"],
            "errors": errors
        }
    
    def process_data(self, state: AgentState) -> AgentState:
        """ìˆ˜ì§‘ëœ ë°ì´í„° ì²˜ë¦¬ ë° ì •ì œ"""
        console.print("\n[bold magenta]ðŸ”§ Processing data...[/bold magenta]")
        
        # LLMì´ ë°ì´í„° ì²˜ë¦¬ ì½”ë“œ ìƒì„±
        result = self.execute_llm_generated_code(
            "Load data/research_data.csv and perform thorough data processing: "
            "1. Handle missing values "
            "2. Remove outliers or cap extreme values "
            "3. Create summary statistics and distributions "
            "4. Add derived features useful for the analysis "
            "5. Create visualizations showing data quality "
            "6. Save processed data as data/processed_data.csv "
            "7. Save summary statistics as data/summary_stats.json",
            context=state["research_data"]
        )
        
        # ì˜¤ë¥˜ê°€ ìžˆëŠ”ì§€ í™•ì¸
        errors = state["errors"]
        if result["error"]:
            errors.append("Error processing data")
        
        return {
            **state,
            "research_data": {
                **state["research_data"],
                "processing_output": result["output"],
                "available_files": result["files"]
            },
            "completed_tasks": state["completed_tasks"] + ["process_data"],
            "errors": errors
        }
    
    def analyze_data(self, state: AgentState) -> AgentState:
        """ì²˜ë¦¬ëœ ë°ì´í„°ì— ëŒ€í•œ ë¶„ì„ ìˆ˜í–‰"""
        console.print("\n[bold magenta]ðŸ“ˆ Analyzing data...[/bold magenta]")
        
        # ì‚¬ìš©í•  ìµœì ì˜ ë°ì´í„° íŒŒì¼ ì°¾ê¸° (ì²˜ë¦¬ëœ ë°ì´í„° ìš°ì„ )
        available_files = state["research_data"].get("available_files", [])
        data_file = 'data/processed_data.csv' if 'data/processed_data.csv' in available_files else 'data/research_data.csv'
        
        # ë¶„ì„ì„ ì•ˆë‚´í•  ì´í•´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        understanding = state["research_data"].get("query_understanding", {})
        
        # LLMì´ ì—°êµ¬ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ì½”ë“œ ìƒì„±
        result = self.execute_llm_generated_code(
            f"Load {data_file} and perform comprehensive analysis for: {state['research_query']}. "
            "Your analysis should include: "
            "1. Trend analysis over time for satisfaction metrics "
            "2. Correlation analysis between satisfaction and repeat purchases "
            "3. Customer segmentation based on behavior patterns "
            "4. Feature importance for factors driving repeat purchases "
            "5. Create visualizations saved to the visualizations/ directory "
            "6. Save analysis results as data/analysis_results.json",
            context={
                "query": state["research_query"],
                "understanding": understanding,
                "available_files": state["research_data"].get("available_files", [])
            }
        )
        
        # ì˜¤ë¥˜ê°€ ìžˆëŠ”ì§€ í™•ì¸
        errors = state["errors"]
        if result["error"]:
            errors.append("Error analyzing data")
        
        return {
            **state,
            "research_data": {
                **state["research_data"],
                "analysis_output": result["output"],
                "available_files": result["files"]
            },
            "completed_tasks": state["completed_tasks"] + ["analyze_data"],
            "errors": errors
        }
    
    def generate_insights(self, state: AgentState) -> AgentState:
        """ì´ì „ ë‹¨ê³„ì˜ ì„±ê³µ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì¸ì‚¬ì´íŠ¸ê°€ í¬í•¨ëœ ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        console.print("\n[bold magenta]ðŸ’¡ Generating insights and report...[/bold magenta]")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        available_files = state["research_data"].get("available_files", [])
        if not available_files:
            available_files = self._refresh_file_list()
            
        # íŠ¹ì • íŒŒì¼ ìœ í˜• í•„í„°ë§
        data_files = [f for f in available_files if f.endswith('.csv') or f.endswith('.json')]
        viz_files = [f for f in available_files if f.endswith(('.png', '.jpg', '.jpeg', '.svg'))]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        analysis_data = {}
        if 'data/analysis_results.json' in available_files:
            try:
                result = self.code_client.invoke("readFiles", {"paths": ["data/analysis_results.json"]})
                analysis_content = self._extract_output(result)
                analysis_data = json.loads(analysis_content) if analysis_content else {}
            except Exception:
                console.print("[yellow]Could not load analysis results[/yellow]")
        
        # LLMìœ¼ë¡œ ì§ì ‘ ë³´ê³ ì„œ ìƒì„±
        prompt = f"""Create a comprehensive markdown research report for: {state['research_query']}

Available data files: {data_files}
Available visualizations: {viz_files}
Completed research steps: {state['completed_tasks']}
Analysis results: {json.dumps(analysis_data, indent=2)[:1000] if analysis_data else 'Not available'}

The report should include:
1. Executive summary
2. Key findings with supporting data
3. Methodology section
4. Analysis of factors driving customer satisfaction
5. Analysis of factors driving repeat purchases
6. Actionable recommendations for businesses
7. References to any visualizations using markdown image syntax: ![description](filename)

Format as a complete professional markdown document with proper headings, bullet points, and formatting.
"""
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        report_content = response.content
        
        # ë³´ê³ ì„œë¥¼ íŒŒì¼ë¡œ ì €ìž¥
        try:
            save_result = self.code_client.invoke("executeCode", {
                "code": f"import os\nos.makedirs('reports', exist_ok=True)\nwith open('reports/final_report.md', 'w') as f:\n    f.write('''{report_content}''')\nprint('Report saved successfully to reports/final_report.md')",
                "language": "python"
            })
            console.print(self._extract_output(save_result))
        except Exception as e:
            console.print(f"[yellow]Could not save report file: {e}[/yellow]")
        
        # ë³´ê³ ì„œ í‘œì‹œ
        console.print("\n[bold green]ðŸ“„ Final Report:[/bold green]")
        console.print("="*60)
        
        try:
            # Markdown ë Œë”ë§ ì‹œë„
            md = Markdown(report_content[:5000] + ("..." if len(report_content) > 5000 else ""))
            console.print(md)
        except Exception:
            # Markdown ë Œë”ë§ì´ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
            console.print(report_content[:2000] + "..." if len(report_content) > 2000 else report_content)
        
        console.print("="*60)
        
        # ë³´ê³ ì„œì™€ í•¨ê»˜ ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ë°˜í™˜
        return {
            **state,
            "messages": state["messages"] + [AIMessage(content=report_content)],
            "research_data": {
                **state["research_data"],
                "final_report": report_content
            },
            "completed_tasks": state["completed_tasks"] + ["generate_insights"]
        }


async def run_research(query: str):
    """LLMì´ ìƒì„±í•œ ì½”ë“œë¡œ ì—°êµ¬ ì‹¤í–‰"""
    console.print(Panel(
        f"[bold cyan]ðŸš€ Dynamic Research Agent[/bold cyan]\n\n"
        f"Research Query: {query}\n\n"
        "[dim]Using Bedrock-AgentCore Code Interpreter with LLM-generated code[/dim]",
        border_style="blue"
    ))
    
    # Context managerë¡œ ë¦¬ì†ŒìŠ¤ ìžë™ ì •ë¦¬
    with ResearchAgent() as agent:
        workflow = agent.create_workflow()
        
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "research_query": query,
            "code_session_id": agent.code_session_id,
            "research_data": {},
            "completed_tasks": [],
            "errors": []
        }
        
        # ì›Œí¬í”Œë¡œìš° ë¹„ë™ê¸° ì‹¤í–‰
        final_state = await workflow.ainvoke(initial_state)
        
        # ì—°êµ¬ ì¤‘ ìƒì„±ëœ ëª¨ë“  íŒŒì¼ ë‚˜ì—´
        console.print("\n[bold]Files created during research:[/bold]")
        files = agent._refresh_file_list()
        for file in files:
            if file.endswith(('/')):
                console.print(f"[blue]ðŸ“ {file}[/blue]")
            elif file.endswith(('.png', '.jpg', '.jpeg', '.svg')):
                console.print(f"[magenta]ðŸ–¼ï¸ {file}[/magenta]")
            elif file.endswith(('.csv', '.json')):
                console.print(f"[yellow]ðŸ“Š {file}[/yellow]")
            elif file.endswith(('.md', '.txt')):
                console.print(f"[green]ðŸ“ {file}[/green]")
            else:
                console.print(f"ðŸ“„ {file}")
        
        console.print(f"\n[bold green]âœ… Research completed with {len(final_state['completed_tasks'])} tasks![/bold green]")
        console.print(f"Completed: {', '.join(final_state['completed_tasks'])}")
        
        if final_state.get("errors"):
            console.print(f"[red]âš ï¸ {len(final_state['errors'])} errors encountered[/red]")
            for error in final_state["errors"]:
                console.print(f"[red]- {error}[/red]")


if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹ì¤„ì—ì„œ ì¿¼ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
    query = " ".join(sys.argv[1:]) if len(sys.argv) > 1 else \
        "Analyze customer satisfaction trends in e-commerce and identify factors that drive repeat purchases"
    
    asyncio.run(run_research(query))